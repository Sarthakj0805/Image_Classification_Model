{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Img_Classification",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1xGMJq0bCgzNE7Zqla_g-_LAKvpmtXPLv",
      "authorship_tag": "ABX9TyMMoFLwuj++8B6xBwqSAJDC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sarthakj0805/Image_Classification_Model/blob/master/Img_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIyrJmOwZEE9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing all the required libraries\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorboard\n",
        "import sys\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "from packaging import version\n",
        "import numpy as np\n",
        "from tensorflow.keras import utils as np_utils\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKZ-CfuMZJJl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load train and test dataset\n",
        "def load_dataset():\n",
        "\t# load dataset\n",
        "\t(trainX, trainY), (testX, testY) = cifar10.load_data()\n",
        "\t# one hot encode target values\n",
        "\ttrainY = tf.keras.utils.to_categorical(trainY)\n",
        "\ttestY = tf.keras.utils.to_categorical(testY)\n",
        "\treturn trainX, trainY, testX, testY\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02VkyHyIY6v_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# summarize loaded dataset\n",
        "def summarize_data():\n",
        "  trainX, trainY, testX, testY = load_dataset()\t\n",
        "  print('Train: X=%s, y=%s' % (trainX.shape, trainY.shape))\n",
        "  print('Test: X=%s, y=%s' % (testX.shape, testY.shape))\n",
        "  # plot first few images\n",
        "  for i in range(9):\n",
        "    # define subplot\n",
        "    plt.subplot(330 + 1 + i)\n",
        "    # plot raw pixel data\n",
        "    plt.imshow(trainX[i])\n",
        "  # show the figure\n",
        "  plt.show()\n",
        "  plt.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjV_C6Z0Za9e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# normalize data\n",
        "def normalize(train, test):\n",
        "\t# convert from integers to floats\n",
        "\ttrain_norm = train.astype('float32')\n",
        "\ttest_norm = test.astype('float32')\n",
        "\t# normalize to range 0-1\n",
        "\ttrain_norm = train_norm - train_norm.min() / train_norm.max() - train_norm.min() \n",
        "\ttest_norm = test_norm - test_norm.min() / test_norm.max() - test_norm.min()\n",
        "\t# return normalized images\n",
        "\treturn train_norm, test_norm\n",
        "\t"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqVXhxlMdZkX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the cnn model\n",
        "def define_model():\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Dropout(0.4))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dense(10, activation='softmax'))\n",
        "  # compile model\n",
        "  opt = SGD(learning_rate=0.005, momentum=0.9)\n",
        "  model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  # print(model.summary())\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "re5TPsgawYw9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot the learning curves for loss and accuracy metrics\n",
        "def summary_plots(history):\n",
        "\tsns.set(context='notebook', palette='bright', style='dark')\n",
        "\t# plot loss\n",
        "\tplt.subplot(211)\n",
        "\tplt.title('Cross Entropy Loss')\n",
        "\tplt.xlabel('epoch')\n",
        "\tplt.ylabel('loss')\n",
        "\tplt.plot(history.history['loss'], color='green', label='train')\n",
        "\tplt.plot(history.history['val_loss'], color='red', label='test')\n",
        "\t# plot accuracy\n",
        "\tplt.subplot(212)\n",
        "\tplt.title('Classification Accuracy')\n",
        "\tplt.xlabel('epoch')\n",
        "\tplt.ylabel('accuracy')\n",
        "\tplt.plot(history.history['accuracy'], color='green', label='train')\n",
        "\tplt.plot(history.history['val_accuracy'], color='red', label='test')\n",
        "\t# save plot to file\n",
        "\tfilename = sys.argv[0].split('/')[-1]\n",
        "\tplt.savefig(filename + '_plot.png')\n",
        "\tplt.show()\n",
        "\tplt.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqQH7wdyZmtn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# run the test harness for evaluating a model\n",
        "def run_model():\n",
        "\t# load dataset\n",
        "\ttrainX, trainY, testX, testY = load_dataset()\n",
        "\t# normalize data\n",
        "\ttrainX, testX = normalize(trainX, testX)\n",
        "\t# define model\n",
        "\tmodel = define_model()\n",
        "\t# create data generator\n",
        "\tdatagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
        "\t# prepare iterator\n",
        "\tit_train = datagen.flow(trainX, trainY, batch_size=64)\n",
        "\t#define the keras tensorboard callback\n",
        "\tlogdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\ttensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "\t# fit model\n",
        "\t# steps = int(trainX.shape[0] / 128)\n",
        "\thistory = model.fit(it_train, steps_per_epoch=300, epochs=100, validation_data=(testX, testY), verbose=1, callbacks=[tensorboard_callback])\n",
        "\t# evaluate model\n",
        "\t_, acc = model.evaluate(testX, testY, verbose=1)\n",
        "\tprint('\\n \\n \\n')\n",
        "\tprint('> %.3f' % (acc * 100.0), \"\\n \\n \\n\")\n",
        "\t# learning curves\n",
        "\tsummary_plots(history)\n",
        "  # save model\n",
        "\t# uncomment to save the model\n",
        "\t# model.save('path to folder')\n",
        "\n",
        "# entry point, run the test harness\n",
        "run_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qm0ohgJJZrE0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "''' to check the model using predictions on the test dataset using the saved model.pb file'''\n",
        "\n",
        "# load dataset\n",
        "trainX, trainY, testX, testY = load_dataset()\n",
        "\n",
        "# normalize data\n",
        "trainX, testX = normalize(trainX, testX)\n",
        "\n",
        "#enter any index between 0-10000 for the test image\n",
        "n = int(input(\"enter n: \"))\n",
        "img = testX[n]\n",
        "\n",
        "# reshape into a single sample with 3 channels\n",
        "img = img.reshape(1, 32, 32, 3)\n",
        "\n",
        "#enter the path to the saved model folder to load the model\n",
        "model = load_model('path to saved model.pb folder')\n",
        "\n",
        "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck' ]\n",
        "result = model.predict(img)\n",
        "\n",
        "print('the selected image is: \\n')\n",
        "plt.imshow(testX[n].astype('uint8'))\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "print(\"the predicted class is : \", classes[np.argmax(result)], \"\\n\")\n",
        "print(\"the correct class is : \" , classes[np.argmax(testY[n])], \"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvhFOgDIcY3i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''test the model on sample images using saved model.pb file'''\n",
        "# load and prepare the image\n",
        "def load_image(filename):\n",
        "\t# load the image\n",
        "\timg = load_img(filename, target_size=(32, 32))\n",
        "\t# convert to array\n",
        "\timg = img_to_array(img)\n",
        "\t# reshape into a single sample with 3 channels\n",
        "\timg = img.reshape(1, 32, 32, 3)\n",
        "\t# prepare pixel data\n",
        "\timg = img.astype('float32')\n",
        "\timg = img - img.min() / img.max() - img.min()\n",
        "\treturn img\n",
        "\n",
        "#enter the path to the saved model folder to load the model\n",
        "model = load_model('path to saved model folder')\n",
        "\n",
        "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck' ]\n",
        "\n",
        "sample_img = ['cat.jpg', 'dog.png', 'airplane.jpg']\n",
        "for i in sample_img:\n",
        "  print(i)\n",
        "  #enter the path to the saved Assets folder to load the images\n",
        "  img = load_image('path to the Assets folder' + str(i))\n",
        "  result = model.predict(img)\n",
        "\n",
        "  print('the selected image is: \\n')\n",
        "  plt.imshow(img.reshape(32,32,3).astype('uint8'))\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "\n",
        "  print(\"the predicted class is : \", classes[np.argmax(result)], '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}